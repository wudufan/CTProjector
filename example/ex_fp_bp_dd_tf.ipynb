{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example of tensorflow(keras)-based distance driven 2d forward and backprojection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ct_projector.projector.tensorflow as ct_projector_tf\n",
    "import ct_projector.projector.tensorflow.circular_2d as ct_circular_tf\n",
    "import ct_projector.projector.tensorflow.filters as ct_filters_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a sample CT image\n",
    "filename = './3.nii.gz'\n",
    "ct = sitk.ReadImage(filename)\n",
    "spacing = ct.GetSpacing()\n",
    "img = sitk.GetArrayFromImage(ct)\n",
    "\n",
    "# convert image from HU to attenuation coefficient\n",
    "# This is the approximate relationship\n",
    "img = (img.astype(np.float32) + 1024) / 1000 * 0.019\n",
    "img[img < 0] = 0\n",
    "\n",
    "img = img[200:232]\n",
    "\n",
    "# also convert to image to our projector dimension batch, z, y, x\n",
    "img = img[::-1, ...]\n",
    "spacing = np.array(spacing[::-1])\n",
    "\n",
    "vmin = -350 / 1000 * 0.019\n",
    "vmax = 1150 / 1000 * 0.019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the ct images\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.subplot(131); plt.imshow(img[img.shape[0]//2, ...], 'gray', aspect=spacing[1] / spacing[2], vmin=vmin, vmax=vmax)\n",
    "plt.subplot(132); plt.imshow(img[:, img.shape[1]//2, :], 'gray', aspect=spacing[0] / spacing[2], vmin=vmin, vmax=vmax)\n",
    "plt.subplot(133); plt.imshow(img[..., img.shape[2]//2], 'gray', aspect=spacing[0] / spacing[1], vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projector holds the default parameters for the forward and backprojection. \n",
    "\n",
    "However, all the projection parameters are passed during calculation to enable training with various geometry. The only constraint is that within one batch the input images must be of the same shape, otherwise they cannot be passed as tensors `[batch, nx, ny, nz, channel]`. The output images must also have the same shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the projector\n",
    "projector = ct_projector_tf.ct_projector()\n",
    "projector.from_file('./projector_fan.cfg')\n",
    "projector.nx = img.shape[2]\n",
    "projector.ny = img.shape[1]\n",
    "projector.nz = 1\n",
    "projector.dx = spacing[2]\n",
    "projector.dy = spacing[1]\n",
    "projector.dz = spacing[0]\n",
    "projector.nv = 1\n",
    "projector.nview = 768\n",
    "\n",
    "angles = projector.get_angles()\n",
    "\n",
    "for k in vars(projector):\n",
    "    print (k, '=', getattr(projector, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = img[:, np.newaxis, :, :, np.newaxis]\n",
    "input_tensor = tf.convert_to_tensor(img_input, tf.float32)\n",
    "print(input_tensor.shape)\n",
    "\n",
    "fp_model = ct_circular_tf.DistanceDriven2DFP(\n",
    "    projector,\n",
    "    angles,\n",
    "    ct_circular_tf.TypeGeometry.PARALLEL,\n",
    "    ct_circular_tf.TypeProjector.IR,\n",
    ")\n",
    "\n",
    "bp_model = ct_circular_tf.DistanceDriven2DBP(\n",
    "    projector,\n",
    "    angles,\n",
    "    ct_circular_tf.TypeGeometry.PARALLEL,\n",
    "    ct_circular_tf.TypeProjector.FORCE_FBP,\n",
    ")\n",
    "\n",
    "filter_model = ct_filters_tf.ProjectionFilter(\n",
    "    projector.du,\n",
    "    ct_circular_tf.TypeGeometry.PARALLEL,\n",
    "    ct_filters_tf.TypeFilter.RL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    t.watch(input_tensor)\n",
    "    fp_tensor = fp_model(input_tensor)\n",
    "    loss = tf.reduce_sum(fp_tensor * fp_tensor / 2)\n",
    "grad_tensor = t.gradient(loss, input_tensor)\n",
    "\n",
    "fprj_tensor = filter_model(fp_tensor)\n",
    "bp_tensor = bp_model(fprj_tensor)\n",
    "\n",
    "print(fp_tensor.shape)\n",
    "print(bp_tensor.shape)\n",
    "print(grad_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = fp_tensor.numpy()\n",
    "plt.figure()\n",
    "plt.imshow(fp[fp.shape[0] // 2, :, 0, :, 0], 'gray', vmin=0, vmax=10)\n",
    "\n",
    "bp = bp_tensor.numpy()\n",
    "plt.figure()\n",
    "plt.imshow(bp[bp.shape[0] // 2, 0, :, :, 0], 'gray', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = grad_tensor.numpy()\n",
    "print(np.abs(grad - bp).max())\n",
    "plt.imshow(grad[grad.shape[0] // 2, 0, :, :, 0], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from ct_projector.projector.cupy.parallel import distance_driven_fp, distance_driven_bp, ramp_filter\n",
    "\n",
    "cuimg = cp.array(img, order='C')[:, cp.newaxis, :, :]\n",
    "cuangles = cp.array(angles, order='C')\n",
    "cufp_ref = distance_driven_fp(projector, cuimg, cuangles)\n",
    "\n",
    "fp_ref = cufp_ref.get()\n",
    "fp_ref = fp_ref[..., np.newaxis]\n",
    "plt.figure()\n",
    "plt.imshow(fp_ref[fp_ref.shape[0] // 2, :, 0, :, 0], 'gray', vmin=0, vmax=10)\n",
    "\n",
    "cufprj_ref = ramp_filter(projector, cufp_ref, 'RL')\n",
    "\n",
    "cubp_ref = distance_driven_bp(projector, cufprj_ref, cuangles, is_fbp=True)\n",
    "bp_ref = cubp_ref.get()\n",
    "bp_ref = bp_ref[..., np.newaxis]\n",
    "plt.figure()\n",
    "plt.imshow(bp_ref[bp_ref.shape[0] // 2, 0, :, :, 0], 'gray', vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow((bp - bp_ref)[bp_ref.shape[0] // 2, 0, :, :, 0], 'gray', vmin=-0.001, vmax=0.001)\n",
    "\n",
    "print(np.abs(fp - fp_ref).max())\n",
    "print(np.abs(bp - bp_ref).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test training\n",
    "fp_input = fp[:, :, 0, :, :]\n",
    "label = img_input * 1.1\n",
    "model_input = tf.keras.layers.Input(shape=[fp.shape[1], fp.shape[3], 1])\n",
    "x = tf.keras.layers.Conv2D(1, 1, padding='same', use_bias=False)(model_input)\n",
    "x = x[:, :, tf.newaxis, :, :]\n",
    "x = filter_model(x)\n",
    "x = bp_model(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=model_input, outputs=x)\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(fp_input, label, batch_size=4, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(fp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(label[label.shape[0] // 2, 0, :, :, 0], 'gray', vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pred[pred.shape[0] // 2, 0, :, :, 0], 'gray', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
