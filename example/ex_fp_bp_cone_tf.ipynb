{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example of tensorflow(keras)-based siddon cone forward and backprojection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ct_projector.projector.tensorflow as ct_projector_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a sample CT image\n",
    "filename = './3.nii.gz'\n",
    "ct = sitk.ReadImage(filename)\n",
    "spacing = ct.GetSpacing()\n",
    "img = sitk.GetArrayFromImage(ct)\n",
    "\n",
    "# convert image from HU to attenuation coefficient\n",
    "# This is the approximate relationship\n",
    "img = (img.astype(np.float32) + 1024) / 1000 * 0.019\n",
    "img[img < 0] = 0\n",
    "\n",
    "# also convert to image to our projector dimension batch, z, y, x\n",
    "img = img[np.newaxis,...]\n",
    "img = img[:, ::-1, ...]\n",
    "spacing = np.array(spacing[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the ct images\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.subplot(131); plt.imshow(img[0, img.shape[1]//2, ...], 'gray', aspect=spacing[1] / spacing[2])\n",
    "plt.subplot(132); plt.imshow(img[0, :, img.shape[2]//2, :], 'gray', aspect=spacing[0] / spacing[2])\n",
    "plt.subplot(133); plt.imshow(img[0, ..., img.shape[3]//2], 'gray', aspect=spacing[0] / spacing[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projector holds the default parameters for the forward and backprojection. \n",
    "\n",
    "However, all the projection parameters are passed during calculation to enable training with various geometry. The only constraint is that within one batch the input images must be of the same shape, otherwise they cannot be passed as tensors `[batch, nx, ny, nz, channel]`. The output images must also have the same shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the projector\n",
    "projector = ct_projector_tf.ct_projector()\n",
    "projector.from_file('./projector.cfg')\n",
    "projector.nx = img.shape[3]\n",
    "projector.ny = img.shape[2]\n",
    "projector.nz = img.shape[1]\n",
    "projector.dx = spacing[2]\n",
    "projector.dy = spacing[1]\n",
    "projector.dz = spacing[0]\n",
    "\n",
    "for k in vars(projector):\n",
    "    print (k, '=', getattr(projector, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the positions of projections\n",
    "angles = np.array([0, 90]) * np.pi / 180\n",
    "\n",
    "srcs = np.array([projector.dso * np.cos(angles), \n",
    "                 projector.dso * np.sin(angles), \n",
    "                 [0] * len(angles)]).T\n",
    "\n",
    "det_centers = np.array([(projector.dso - projector.dsd) * np.cos(angles), \n",
    "                        (projector.dso - projector.dsd) * np.sin(angles), \n",
    "                        [0] * len(angles)]).T\n",
    "\n",
    "det_us = np.array([-np.sin(angles), np.cos(angles), [0] * len(angles)]).T\n",
    "det_vs = np.zeros_like(det_us)\n",
    "det_vs[:, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the geometry. In this example, we will generate one projection for each image in the batch. \n",
    "# The first image will take a 0-deg projection, the second image will take a 90-deg projection.\n",
    "geometry = projector.make_geometry(det_centers, det_us, det_vs, srcs)\n",
    "\n",
    "'''\n",
    "The geometry is in the shape of [2, 4, 3]\n",
    "2 is the batchsize, 4 is corresponding to nview = 1, 3 is the vector in 3-dimension space. \n",
    "The organization is:\n",
    "\n",
    "geometry[0]: \n",
    "    det_center: (x0,y0,z0), (x1,y1,z1)...\n",
    "    det_u: (x0,y0,z0), (x1,y1,z1)...\n",
    "    det_v: (x0,y0,z0), (x1,y1,z1)...\n",
    "    src: (x0,y0,z0), (x1,y1,z1)...\n",
    "geometry[1]: \n",
    "    det_center: (x0,y0,z0), (x1,y1,z1)...\n",
    "    det_u: (x0,y0,z0), (x1,y1,z1)...\n",
    "    det_v: (x0,y0,z0), (x1,y1,z1)...\n",
    "    src: (x0,y0,z0), (x1,y1,z1)...\n",
    "\n",
    "'''\n",
    "geometry = np.reshape(geometry, [4, len(angles), 3]).transpose([1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's set two images in one batch. The second image is upside down.\n",
    "img1 = np.copy(img)[...,np.newaxis]\n",
    "img2 = np.copy(img)[...,np.newaxis]\n",
    "img2 = img2[:, ::-1, ...]\n",
    "imgs = np.concatenate((img1, img2), 0).transpose([0, 3, 2, 1, 4])\n",
    "print (imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The ground truth from eager excution. \n",
    "Note than we generated projection with size [batch, nu, nv, nview, channel]\n",
    "The projection[batch=0] is corresponding to the first image with geometry at 0-deg;\n",
    "The projection[batch=1] is corresponding to the second image (upside down) with geometry at 90-deg.\n",
    "\n",
    "We multiply it by 1.5 so we can test the training function\n",
    "'''\n",
    "label = ct_projector_tf.SiddonConeFP(projector)(imgs, geometry = geometry).numpy() * 1.5\n",
    "print (label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the keras interface for building the model. The module can be used as any other keras modules. The gradient will be automatically calculated. \n",
    "\n",
    "Note that our FP module takes multiple inputs. \n",
    "The image is through the positional argument inputs, the geometry and other informations are through the keyword arguments. \n",
    "However, gradient will only flow to the image input. \n",
    "'''\n",
    "\n",
    "K.clear_session()\n",
    "img_input = tf.keras.Input(shape = [projector.nx, projector.ny, projector.nz, 1])\n",
    "# geometry input. Note that this is for one image. Keras will automatically add the batch dimension.\n",
    "geo_input = tf.keras.Input(shape = [4, 3])\n",
    "# a very simple model: 1x1 convolution with good intialization\n",
    "x = tf.keras.layers.Conv3D(1, 1, padding='same', kernel_initializer=tf.keras.initializers.Ones())(img_input)\n",
    "\n",
    "# add our forward projection module here\n",
    "fp_tensor = ct_projector_tf.SiddonConeFP(projector)(x, geometry = geo_input)\n",
    "\n",
    "model = tf.keras.Model(inputs = [img_input, geo_input], outputs = fp_tensor)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss = tf.keras.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model and observe the loss will drop\n",
    "model.fit(x = [imgs, geometry], y = label, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can verify the forward projection\n",
    "fp = model.predict([imgs, geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the projections\n",
    "plt.figure(figsize = (len(angles)*8,4))\n",
    "for i in range(len(angles)):\n",
    "    plt.subplot(1,len(angles)*2,i+1); plt.title('label')\n",
    "    plt.imshow(label[i, ..., 0, 0].T, 'gray', vmin=0, vmax=10)\n",
    "for i in range(len(angles)):\n",
    "    plt.subplot(1,len(angles)*2,i+3); plt.title('predicted')\n",
    "    plt.imshow(fp[i, ..., 0, 0].T, 'gray', vmin=0, vmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced usage: set the grid, detector and output_shape for each individual image/batch\n",
    "\n",
    "- The grid and detector can be set differently within a batch\n",
    "- The output_shape can be set for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "img_input = tf.keras.Input(shape = [projector.nx, projector.ny, projector.nz, 1])\n",
    "geo_input = tf.keras.Input(shape = [4, 3])\n",
    "grid_input = tf.keras.Input(shape = [6])\n",
    "det_input = tf.keras.Input(shape = [4])\n",
    "shape_input = tf.keras.Input(shape = [3], dtype = tf.int32)\n",
    "\n",
    "# Let's set to use the same nu but different nv\n",
    "fp_tensor = ct_projector_tf.SiddonConeFP(projector, default_shape = [-1, -1, 2048])(\n",
    "    img_input, geometry = geo_input, grid = grid_input, detector = det_input, output_shape = shape_input)\n",
    "print (fp_tensor)\n",
    "\n",
    "model = tf.keras.Model(inputs = [img_input, geo_input, grid_input, det_input, shape_input], outputs = fp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "grid: we used the same grid for the two images in this batch\n",
    "det: we used different detector settings;\n",
    "output_shape: Note that output_shape[0] need to be compatible with nview derived from geometry. We can only override nv, because nu is preset by default_shape\n",
    "'''\n",
    "\n",
    "grid = np.array([[projector.dx, projector.dy, projector.dz, projector.cx, projector.cy, projector.cz]]*2, np.float32)\n",
    "det = np.array([[projector.du, projector.dv, projector.off_u, projector.off_v], \n",
    "                [projector.du * 0.75, projector.dv * 0.75, 500, 0]], np.float32)\n",
    "output_shape = np.array([[1, projector.nv // 2, projector.nu // 2]]*2, np.int32)\n",
    "fp = model.predict([imgs, geometry, grid, det, output_shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (len(angles)*4,4))\n",
    "for i in range(len(angles)):\n",
    "    plt.subplot(1,len(angles),i+1); plt.title('predicted')\n",
    "    plt.imshow(fp[i, ..., 0, 0].T, 'gray', vmin=0, vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this case we will use different number of projections (different length of geometry) for different batches\n",
    "\n",
    "To enable this feature, we need to:\n",
    "(1) set geo_input shape to [None, 3]\n",
    "(2) set default_shape to [-1, ...]\n",
    "'''\n",
    "K.clear_session()\n",
    "img_input = tf.keras.Input(shape = [projector.nx, projector.ny, projector.nz, 1])\n",
    "geo_input = tf.keras.Input(shape = [None, 3])\n",
    "grid_input = tf.keras.Input(shape = [6])\n",
    "# we will use the same detector settings\n",
    "det_input = np.array([projector.du * 0.75, projector.dv * 0.75, 250, 0], np.float32)\n",
    "\n",
    "# Let's set to use the same nu but different nv\n",
    "fp_tensor = ct_projector_tf.SiddonConeFP(projector, default_shape = [-1, 2048, 2048])(\n",
    "    img_input, geometry = geo_input, grid = grid_input, detector = det_input)\n",
    "print (fp_tensor)\n",
    "\n",
    "model = tf.keras.Model(inputs = [img_input, geo_input, grid_input], outputs = fp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1: batch = 2, one projection for each image\n",
    "grid = np.array([[projector.dx, projector.dy, projector.dz, projector.cx, projector.cy, projector.cz], \n",
    "                 [projector.dx, projector.dy, projector.dz, projector.cx, projector.cy, projector.cz + 50]], np.float32)\n",
    "fp = model.predict([imgs, geometry, grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (len(angles)*4,4))\n",
    "for i in range(len(angles)):\n",
    "    plt.subplot(1,len(angles),i+1); plt.title('predicted')\n",
    "    plt.imshow(fp[i, ..., 0, 0].T, 'gray', vmin=0, vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2: batch = 1, two projections for the image\n",
    "grid = np.array([[projector.dx, projector.dy, projector.dz, projector.cx, projector.cy, projector.cz]], np.float32)\n",
    "geo = geometry.transpose([1,0,2]).reshape([-1, 3])[np.newaxis]\n",
    "fp = model.predict([imgs[[0]], geo, grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (len(angles)*4,4))\n",
    "for i in range(len(angles)):\n",
    "    plt.subplot(1,len(angles),i+1); plt.title('predicted')\n",
    "    plt.imshow(fp[0, ..., i, 0].T, 'gray', vmin=0, vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
